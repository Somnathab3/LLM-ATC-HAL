# LLM-ATC-HAL: Embodied LLM Air Traffic Controller with Hallucination Detection

![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)
![Status](https://img.shields.io/badge/status-production--ready-green.svg)
![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)

A comprehensive framework for testing and mitigating hallucinations in Large Language Model-based Air Traffic Control systems with ICAO-compliant safety metrics and real-time experience replay.

## üéØ Quick Start

```bash
# Clone and setup
git clone https://github.com/Somnathab3/LLM-ATC-HAL
cd LLM-ATC-HAL
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install Ollama models
ollama pull llama3.1:8b
ollama pull mistral:7b
ollama pull codellama:7b

# Run system validation
python deficiency_check_fixed.py

# Execute comprehensive testing
python comprehensive_hallucination_tester_v2.py
```


## üèóÔ∏è System Architecture

```
LLM-ATC-HAL/
‚îú‚îÄ‚îÄ analysis/                     # Hallucination Detection & Analysis
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_hallucination_detection.py  # 6-layer detection framework
‚îÇ   ‚îú‚îÄ‚îÄ hallucination_taxonomy.py           # Classification system
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                          # Performance evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualisation.py                   # Research visualization tools
‚îú‚îÄ‚îÄ llm_atc/                     # Core LLM-ATC Framework
‚îÇ   ‚îú‚îÄ‚îÄ agents/                  # Multi-Agent Controller System
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controller_interface.py         # Main ATC controller interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py                     # Resolution execution engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ planner.py                      # Conflict resolution planner
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scratchpad.py                   # Reasoning trace system
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verifier.py                     # Safety verification agent
‚îÇ   ‚îú‚îÄ‚îÄ baseline_models/         # Traditional ATC Models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conflict_detector.py            # Classical conflict detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conflict_resolver.py            # Rule-based resolution
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py                     # Baseline performance evaluation
‚îÇ   ‚îú‚îÄ‚îÄ memory/                  # Experience Replay System
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ replay_store.py                 # Vector-based storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ experience_integrator.py        # Memory integration
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                 # ICAO Safety Quantification
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ safety_margin_quantifier.py     # Safety compliance metrics
‚îÇ   ‚îú‚îÄ‚îÄ tools/                   # Specialized ATC Tools
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bluesky_tools.py                # BlueSky simulation interface
‚îÇ   ‚îú‚îÄ‚îÄ data/                    # Training & validation datasets
‚îÇ   ‚îú‚îÄ‚îÄ experiments/             # Research experiment configurations
‚îÇ   ‚îî‚îÄ‚îÄ cli.py                   # Command-line interface
‚îú‚îÄ‚îÄ llm_interface/               # Multi-Model LLM Ensemble
‚îÇ   ‚îú‚îÄ‚îÄ ensemble.py              # Weighted consensus system
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py           # Primary LLM interface
‚îÇ   ‚îî‚îÄ‚îÄ prompts.py              # ATC-specific prompts
‚îú‚îÄ‚îÄ testing/                     # Comprehensive Testing Framework
‚îÇ   ‚îú‚îÄ‚îÄ test_executor.py         # Test execution engine
‚îÇ   ‚îú‚îÄ‚îÄ scenario_manager.py      # BlueSky scenario generation
‚îÇ   ‚îî‚îÄ‚îÄ result_analyzer.py       # Statistical analysis
‚îú‚îÄ‚îÄ scenarios/                   # Monte Carlo Testing
‚îÇ   ‚îî‚îÄ‚îÄ monte_carlo_framework.py # BlueSky-integrated scenarios
‚îú‚îÄ‚îÄ solver/                      # Conflict Resolution Engine
‚îÇ   ‚îî‚îÄ‚îÄ conflict_solver.py       # Advanced conflict resolution algorithms
‚îî‚îÄ‚îÄ comprehensive_hallucination_tester_v2.py  # Main testing suite
```

## üöÄ Core Features

### üîç **Hallucination Detection System**
- **6-Layer Detection Framework**: MIND framework, attention patterns, semantic entropy
- **Multi-Model Consensus**: Cross-validation between llama3.1:8b, mistral:7b, codellama:7b
- **Real-Time Classification**: Fabrication, omission, contradiction, uncertainty collapse detection
- **Safety Impact Assessment**: Critical safety analysis for aviation context

### üõ°Ô∏è **ICAO-Compliant Safety Metrics**
- **Safety Margin Quantification**: Horizontal/vertical separation standards
- **Risk Assessment**: Real-time compliance validation
- **Critical Threshold Monitoring**: Automated safety boundary enforcement
- **Performance Tracking**: Statistical safety compliance reporting

### üß† **Experience Replay System**
- **Vector Storage**: 1024-dim embeddings with Chroma HNSW
- **Similarity Search**: Metadata-filtered experience retrieval
- **Continuous Learning**: Conflict resolution pattern recognition
- **Local Embeddings**: Privacy-preserving intfloat/e5-large-v2 model

### üéÆ **BlueSky Simulation Integration**
- **Realistic Scenarios**: Range-based parameter sampling
- **ICAO Callsigns**: Authentic aviation data
- **Environmental Modeling**: Weather, turbulence, traffic density
- **Monte Carlo Testing**: Statistical scenario generation

## üìã Installation & Setup

### Prerequisites
```bash
# Required software
Python 3.9+
Ollama (for LLM models)
Git (for cloning)

# Optional for enhanced performance
NVIDIA GPU with CUDA support
Docker (for Milvus vector database)
```

### Step 1: Environment Setup
```bash
# Clone repository
git clone https://github.com/Somnathab3/LLM-ATC-HAL
cd LLM-ATC-HAL

# Create virtual environment
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# Linux/macOS:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Step 2: Ollama Model Installation
```bash
# Install required LLM models
ollama pull llama3.1:8b        # Primary reasoning model
ollama pull mistral:7b         # Validation model  
ollama pull codellama:7b       # Technical analysis model

# Verify installation
ollama list
```

### Step 3: System Validation
```bash
# Run comprehensive system check
python deficiency_check_fixed.py

# Expected output: All checks passed!
# Validates: imports, Ollama connectivity, scenario generation,
# hallucination detection, safety quantification
```

## üéØ Usage Guide

### Quick System Test
```bash
# Run fast validation test (16 scenarios)
python quick_test_runner.py

# Expected results:
# - Total Tests: 16
# - Error Rate: 0.00%
# - ICAO Compliance: 62.50%+
```

### Comprehensive Testing Campaign
```bash
# Full testing suite (default configuration)
python comprehensive_hallucination_tester_v2.py

# Features tested:
# ‚úÖ System validation (15 components)
# ‚úÖ Multi-model ensemble testing
# ‚úÖ BlueSky scenario generation
# ‚úÖ Hallucination detection (6 layers)
# ‚úÖ ICAO safety compliance
# ‚úÖ Statistical analysis & visualization
```

### Individual Component Testing
```bash
# Test specific components
python system_validation.py           # System health check
python -m testing.test_executor       # Test execution engine
python -m analysis.enhanced_hallucination_detection  # Detection algorithms
```

## üìö Core Modules & Functions

### 1. **Hallucination Detection** (`analysis/`)

#### `enhanced_hallucination_detection.py`
```python
from analysis.enhanced_hallucination_detection import EnhancedHallucinationDetector

detector = EnhancedHallucinationDetector()
result = detector.detect_hallucinations(llm_response, context, scenario_data)

# Returns: HallucinationResult with detection confidence, types, evidence
# Detection Layers: MIND framework, semantic entropy, self-consistency
```

#### `hallucination_taxonomy.py`
```python
from analysis.hallucination_taxonomy import HallucinationType, HallucinationClassifier

# Classification types: FABRICATION, OMISSION, IRRELEVANCY, 
# CONTRADICTION, SEMANTIC_DRIFT, UNCERTAINTY_COLLAPSE
classifier = HallucinationClassifier()
classification = classifier.classify_hallucination(response, context)
```

#### `metrics.py`
```python
from analysis.metrics import PerformanceMetrics, SafetyMetrics

# Calculate comprehensive performance scores
metrics = PerformanceMetrics()
safety_score = metrics.calculate_safety_score(resolution_data)
hallucination_rate = metrics.calculate_hallucination_rate(detection_results)
```

### 2. **LLM Ensemble System** (`llm_interface/`)

#### `ensemble.py`
```python
from llm_interface.ensemble import OllamaEnsembleClient

ensemble = OllamaEnsembleClient()
response = ensemble.query_ensemble(prompt, context, require_json=True)

# Returns: EnsembleResponse with consensus, individual responses, 
# confidence scores, uncertainty metrics
```

#### `llm_client.py`
```python
from llm_interface.llm_client import OllamaClient

client = OllamaClient(model="llama3.1:8b")
response = client.generate_response(prompt, max_tokens=1000, temperature=0.1)
```

#### `prompts.py`
```python
from llm_interface.prompts import ATCPromptGenerator

prompt_gen = ATCPromptGenerator()
atc_prompt = prompt_gen.generate_conflict_prompt(aircraft_data, urgency='high')
system_prompt = prompt_gen.get_system_prompt(role='conflict_resolver')
```

### 3. **Core LLM-ATC Framework** (`llm_atc/`)

The `llm_atc/` directory contains the core framework for LLM-based Air Traffic Control with comprehensive agent architecture, baseline models, and specialized tools.

#### **Agent System** (`llm_atc/agents/`)

##### `controller_interface.py`
```python
from llm_atc.agents.controller_interface import ATCControllerInterface

controller = ATCControllerInterface()
control_decision = controller.process_conflict(aircraft_states, airspace_context)
safety_validation = controller.validate_decision(decision, safety_constraints)
```

##### `executor.py`
```python
from llm_atc.agents.executor import ConflictExecutor

executor = ConflictExecutor()
execution_result = executor.execute_resolution(resolution_plan, real_time_data)
performance_metrics = executor.track_execution_performance()
```

##### `planner.py`
```python
from llm_atc.agents.planner import ConflictPlanner

planner = ConflictPlanner()
resolution_plan = planner.plan_conflict_resolution(scenario_data, constraints)
alternative_plans = planner.generate_alternatives(primary_plan, risk_threshold)
```

##### `scratchpad.py`
```python
from llm_atc.agents.scratchpad import ReasoningScratchpad

scratchpad = ReasoningScratchpad()
reasoning_steps = scratchpad.trace_reasoning(llm_response, decision_context)
explanation = scratchpad.generate_explanation(reasoning_chain)
```

##### `verifier.py`
```python
from llm_atc.agents.verifier import SafetyVerifier

verifier = SafetyVerifier()
safety_check = verifier.verify_resolution(proposed_solution, safety_standards)
compliance_report = verifier.generate_compliance_report(verification_results)
```

#### **Baseline Models** (`llm_atc/baseline_models/`)

##### `conflict_detector.py`
```python
from llm_atc.baseline_models.conflict_detector import BaselineConflictDetector

detector = BaselineConflictDetector()
conflicts = detector.detect_conflicts(aircraft_positions, trajectories)
risk_assessment = detector.assess_conflict_risk(conflict_data)
```

##### `conflict_resolver.py`
```python
from llm_atc.baseline_models.conflict_resolver import BaselineResolver

resolver = BaselineResolver()
baseline_solution = resolver.resolve_conflict(conflict_scenario)
comparison_metrics = resolver.compare_with_llm_solution(llm_solution, baseline_solution)
```

##### `evaluate.py`
```python
from llm_atc.baseline_models.evaluate import BaselineEvaluator

evaluator = BaselineEvaluator()
performance_comparison = evaluator.evaluate_against_baselines(llm_results, scenarios)
benchmark_report = evaluator.generate_benchmark_report(evaluation_data)
```

#### **CLI Interface** (`llm_atc/cli.py`)
```python
# Command-line interface for LLM-ATC operations
# Usage: python -m llm_atc.cli --command validate --config config.yaml

from llm_atc.cli import ATCCommandLineInterface

cli = ATCCommandLineInterface()
cli.run_validation_pipeline()
cli.execute_batch_testing(config_file="test_config.yaml")
```

#### **Data Management** (`llm_atc/data/`)
- **Scenario Storage**: Historical conflict scenarios and resolutions
- **Training Data**: Curated datasets for model training and evaluation
- **Validation Sets**: Standardized test cases for performance benchmarking

#### **Experiments** (`llm_atc/experiments/`)
- **Distribution Shift Studies**: Cross-domain performance analysis
- **Ablation Studies**: Component-wise performance evaluation
- **Comparative Analysis**: LLM vs baseline model comparisons

#### **Safety Metrics** (`llm_atc/metrics/`)

##### `safety_margin_quantifier.py`
```python
from llm_atc.metrics.safety_margin_quantifier import SafetyMarginQuantifier

quantifier = SafetyMarginQuantifier()
safety_result = quantifier.calculate_safety_margins(conflict_geometry, resolution)

# Returns: SafetyMetrics with ICAO compliance, risk assessment,
# horizontal/vertical margins, overall safety score
```

### 7. **BlueSky Integration** (`scenarios/`)

##### `bluesky_tools.py`
```python
from llm_atc.tools.bluesky_tools import BlueSkyInterface

bluesky = BlueSkyInterface()
simulation_commands = bluesky.generate_bluesky_commands(scenario_data)
simulation_results = bluesky.execute_simulation(commands, duration=600)
performance_analysis = bluesky.analyze_simulation_results(results)
```

#### `replay_store.py`
```python
from llm_atc.memory.replay_store import VectorReplayStore

store = VectorReplayStore()
store.store_experience(conflict_experience)  # Store with 1024-dim embeddings
similar_cases = store.retrieve_experience(conflict_desc, k=5)  # Similarity search
```

#### `experience_integrator.py`
```python
from llm_atc.memory.experience_integrator import ExperienceIntegrator

integrator = ExperienceIntegrator(replay_store)
guidance = integrator.get_experience_guidance(current_scenario)
integrator.integrate_experience(scenario, controller_feedback)
```

### 5. **Testing Framework** (`testing/`)

#### `test_executor.py`
```python
from testing import TestExecutor

executor = TestExecutor(ensemble_client, hallucination_detector, safety_quantifier)
results = await executor.execute_test(scenario, models_to_test)

# Returns: List[TestResult] with performance metrics, safety scores,
# hallucination detection results, timing data
```

#### `scenario_manager.py`
```python
from testing import ScenarioManager

manager = ScenarioManager()
scenarios = manager.generate_comprehensive_scenarios(
    num_scenarios=50,
    complexity_distribution={'simple': 0.3, 'moderate': 0.4, 'complex': 0.3}
)
```

#### `result_analyzer.py`
```python
from testing.result_analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()
analysis = analyzer.analyze_test_results(results_list)
analyzer.generate_visualizations(analysis, output_dir="test_results/")
```

### 6. Monte Carlo Analysis & Benchmarking

#### **Monte Carlo Results Analysis** (`llm_atc/metrics/monte_carlo_analysis.py`)

Complete framework for analyzing Monte Carlo simulation results with aggregation and visualization capabilities.

##### `MonteCarloResultsAnalyzer`
```python
from llm_atc.metrics.monte_carlo_analysis import MonteCarloResultsAnalyzer

analyzer = MonteCarloResultsAnalyzer()

# Read results from file
results_df = analyzer.read_results_file("monte_carlo_results.json")

# Compute comprehensive metrics
aggregated_metrics = analyzer.aggregate_monte_carlo_metrics(results_df)

# Individual metric calculations
fp_fn_rates = analyzer.compute_false_positive_negative_rates(results_df)
success_rates = analyzer.compute_success_rates_by_scenario(results_df)
separation_margins = analyzer.compute_average_separation_margins(results_df)
efficiency_penalties = analyzer.compute_efficiency_penalties(results_df)
```

##### `MonteCarloVisualizer`
```python
from llm_atc.metrics.monte_carlo_analysis import MonteCarloVisualizer

visualizer = MonteCarloVisualizer()

# Create performance summary charts
summary_plots = visualizer.create_performance_summary_charts(
    aggregated_metrics, 
    output_dir="monte_carlo_plots"
)

# Create distribution shift analysis plots
shift_plots = visualizer.create_distribution_shift_plots(
    aggregated_metrics,
    output_dir="monte_carlo_plots"
)
```

##### Complete Analysis Pipeline
```python
from llm_atc.metrics.monte_carlo_analysis import analyze_monte_carlo_results

# Run complete analysis from results file
analysis_results = analyze_monte_carlo_results(
    results_file="monte_carlo_results.json",
    output_dir="analysis_output"
)

# Returns: metrics, plots, and file paths
print(f"Metrics saved to: {analysis_results['metrics_file']}")
print(f"Summary plots: {analysis_results['summary_plots']}")
print(f"Distribution shift plots: {analysis_results['distribution_shift_plots']}")
```

#### **Monte Carlo Benchmark CLI**

Run comprehensive Monte Carlo benchmarks via command line:

```bash
# Basic Monte Carlo benchmark
python -m llm_atc.cli monte-carlo-benchmark

# Custom scenario distribution
python -m llm_atc.cli monte-carlo-benchmark \
    --num-horizontal 50 \
    --num-vertical 30 \
    --num-sector 20 \
    --complexities simple,moderate,complex \
    --shift-levels in_distribution,moderate_shift,extreme_shift

# Advanced configuration
python -m llm_atc.cli monte-carlo-benchmark \
    --output results/monte_carlo_2024 \
    --models llama3.1:8b,mistral:7b,codellama:7b \
    --timeout 300 \
    --parallel-workers 4
```

#### **Scenario Types and Configurations**

**Horizontal Scenarios**:
- 2-10 aircraft at the same altitude (FL100-FL410)
- Converging flight paths with potential conflicts
- Horizontal separation margin analysis

**Vertical Scenarios**:
- Aircraft with near-threshold altitude differences (¬±1000ft)
- Climb/descent conflict situations
- Vertical separation margin analysis

**Sector Scenarios**:
- 5-10 aircraft with random positions in sector
- Multiple simultaneous conflicts
- Complex airspace management

#### **Metrics Computed**

**Detection Performance**:
- False Positive Rate: Incorrectly predicted conflicts
- False Negative Rate: Missed actual conflicts
- Precision/Recall for conflict detection

**Success Rates by Scenario Type**:
- Resolution success percentage per scenario category
- Failure analysis and categorization
- Performance degradation under stress

**Safety Margins**:
- Average horizontal separation margins (nautical miles)
- Average vertical separation margins (feet)
- Margin-to-uncertainty ratios
- Safety level classifications (critical, marginal, adequate, excellent)

**Efficiency Penalties**:
- Extra distance traveled due to resolution maneuvers
- Fuel consumption implications
- Time delays introduced

**Distribution Shift Analysis**:
- Performance across in-distribution vs out-of-distribution scenarios
- Robustness metrics under operational stress
- Model degradation patterns

#### **Example Results Structure**

```json
{
  "summary": {
    "total_scenarios": 100,
    "scenario_types": ["horizontal", "vertical", "sector"],
    "analysis_timestamp": "2024-01-15T10:30:00"
  },
  "detection_performance": {
    "false_positive_rate": 0.125,
    "false_negative_rate": 0.087,
    "total_false_positives": 12,
    "total_false_negatives": 8
  },
  "success_rates_by_scenario": {
    "horizontal": {
      "success_rate": 0.85,
      "successful_scenarios": 34,
      "total_scenarios": 40
    },
    "vertical": {
      "success_rate": 0.72,
      "successful_scenarios": 21,
      "total_scenarios": 30
    },
    "sector": {
      "success_rate": 0.63,
      "successful_scenarios": 19,
      "total_scenarios": 30
    }
  },
  "separation_margins": {
    "avg_horizontal_margin": 3.7,
    "avg_vertical_margin": 850.0,
    "std_horizontal_margin": 2.1,
    "std_vertical_margin": 420.0
  },
  "efficiency_metrics": {
    "avg_efficiency_penalty": 4.2,
    "std_efficiency_penalty": 2.8,
    "max_efficiency_penalty": 12.5
  },
  "distribution_shift_analysis": {
    "in_distribution": {
      "scenario_count": 40,
      "false_positive_rate": 0.08,
      "avg_success_rate": 0.82
    },
    "moderate_shift": {
      "scenario_count": 35,
      "false_positive_rate": 0.15,
      "avg_success_rate": 0.71
    },
    "extreme_shift": {
      "scenario_count": 25,
      "false_positive_rate": 0.24,
      "avg_success_rate": 0.58
    }
  }
}
```

#### **Visualization Outputs**

The Monte Carlo analysis generates comprehensive visualizations:

1. **Success Rates by Scenario Type**: Bar chart showing resolution success percentages
2. **Detection Performance**: FP/FN rate comparison charts
3. **Safety Margins**: Horizontal vs vertical separation margin analysis
4. **Distribution Shift Performance**: Scatter plots showing performance degradation
5. **Efficiency Analysis**: Penalty distribution and trend analysis

All plots are saved as high-resolution PNG files with detailed annotations and statistical information.

#### `monte_carlo_framework.py`
```python
from scenarios.monte_carlo_framework import BlueSkyScenarioGenerator, ComplexityTier

generator = BlueSkyScenarioGenerator("scenario_ranges.yaml")
scenario = generator.generate_scenario(ComplexityTier.COMPLEX)

# Generates: Realistic ATC scenarios with ICAO callsigns,
# environmental conditions, BlueSky commands
```

### 7. **Solver System** (`solver/`)

#### `conflict_solver.py`
```python
from solver.conflict_solver import ConflictSolver

solver = ConflictSolver()
resolution = solver.solve_conflict(aircraft_states, safety_constraints)
validation = solver.validate_resolution(resolution, scenario_context)
```

## üîß Configuration Files

### Test Configuration
```python
# comprehensive_hallucination_tester_v2.py
config = TestConfiguration(
    models_to_test=['llama3.1:8b', 'mistral:7b', 'codellama:7b'],
    num_scenarios=10,
    parallel_workers=4,
    timeout_per_test=30.0,
    use_gpu_acceleration=True,
    generate_visualizations=True
)
```

### Scenario Ranges (`scenario_ranges.yaml`)
```yaml
aircraft:
  count: [2, 8]               # Number of aircraft
  
geography:
  latitude: [50.0, 55.0]      # European airspace
  longitude: [3.0, 7.0]
  
weather:
  wind_speed: [0, 50]         # Knots
  turbulence_factor: [0.0, 1.0]
  
conflicts:
  severity: ['minor', 'moderate', 'critical']
  time_to_collision: [30, 600]  # Seconds
```

### Distribution Shift Levels (`distribution_shift_levels.yaml`)
```yaml
tiers:
  in_distribution:
    description: "Normal operational parameters"
    aircraft_count: [2, 4]
    
  out_distribution:
    description: "Edge case operational conditions"  
    aircraft_count: [5, 8]
    
  adversarial:
    description: "Stress testing with extreme conditions"
    aircraft_count: [8, 12]
```

## üìä System Validation Results

Current system status (validated 2025-07-29):

```
‚úÖ All Checks Passed! System ready for testing.

Component Status:
‚úÖ Testing modules imported successfully
‚úÖ LLM interface imported successfully  
‚úÖ Hallucination detection imported successfully
‚úÖ Safety margin quantifier imported successfully
‚úÖ Memory modules imported successfully
‚úÖ Ollama connectivity confirmed
‚úÖ Scenario generation working (8 scenarios)
‚úÖ Safety quantification working
```

## üìà Performance Monitoring

### Real-Time Metrics
- **Response Time**: < 3 seconds (target: < 5s)
- **Memory Usage**: < 8GB RAM
- **GPU Utilization**: NVIDIA GeForce RTX 5070 Ti detected
- **Concurrent Tests**: 4 parallel workers

### Success Criteria
- **Zero Error Rate**: No system failures during execution
- **100% Test Completion**: All scenarios successfully processed
- **ICAO Compliance**: >60% safety standard compliance
- **Hallucination Detection**: <1% false positive rate

## üêõ Troubleshooting

### Common Issues

1. **SentenceTransformers Error**
   ```bash
   # Known issue with corrupted cache
   # System automatically uses fallback embeddings
   # Performance impact: Reduced vector similarity accuracy
   ```

2. **Ollama Connection Issues**
   ```bash
   # Ensure Ollama is running
   ollama serve
   
   # Check model availability
   ollama list
   ```

3. **Import Errors**
   ```bash
   # Verify all dependencies installed
   pip install -r requirements.txt
   
   # Run system validation
   python deficiency_check_fixed.py
   ```

4. **Memory Issues**
   ```bash
   # Reduce parallel workers if memory constrained
   # Edit comprehensive_hallucination_tester_v2.py:
   # parallel_workers=2  # Default: 4
   ```

## üìã Dependencies

### Core Requirements
- **Python**: 3.9+ (tested with 3.12)
- **PyTorch**: 2.1.0+ (GPU acceleration)
- **ChromaDB**: 0.4.24+ (vector storage)
- **Ollama**: Latest (LLM models)
- **BlueSky**: ATC simulation engine
- **Sentence-Transformers**: 2.2.2+ (embeddings)

### Optional Enhancements  
- **NVIDIA CUDA**: GPU acceleration
- **Docker**: Milvus vector database
- **Weights & Biases**: Experiment tracking
- **Plotly**: Interactive visualizations


## üî¨ Research Applications

This framework supports research in:
- **Hallucination Detection**: Multi-modal detection mechanisms
- **Safety-Critical AI**: Real-time safety constraint validation
- **Human-AI Collaboration**: Interactive decision support
- **Embodied AI**: Multi-agent reasoning systems
- **Distribution Shift**: Robustness across operational conditions

## üß™ Development & Testing

### Running Individual Tests
```bash
# Test specific modules
python tests/test_agents_simple.py       # Agent functionality
python tests/test_memory_simple.py       # Memory system  
python tests/test_baseline.py            # Baseline models

# Test with pytest
pytest tests/ -v                         # All tests with verbose output
pytest tests/test_memory_task2.py -k "vector"  # Specific test patterns
```

### Code Quality & Linting
```bash
# Python code formatting (if available)
black llm_atc/ analysis/ testing/        # Code formatting
flake8 .                                  # Style checking

# Type checking (if mypy installed)
mypy llm_atc/                            # Static type analysis
```

### Performance Profiling
```bash
# Memory profiling during tests
python -m memory_profiler comprehensive_hallucination_tester_v2.py

# Timing analysis
python -m cProfile -o profile_results.prof comprehensive_hallucination_tester_v2.py
```

## üìä Example Output

### Successful Test Run
```
=== LLM-ATC Hallucination Testing System ===
üîß System Validation: ‚úÖ PASSED (15/15 components)
üß† LLM Models: llama3.1:8b, mistral:7b, codellama:7b
üìã Test Configuration: 10 scenarios, 4 workers, 30s timeout

üéØ Scenario Generation: ‚úÖ 10 scenarios generated
üîç Hallucination Detection: ‚úÖ 6-layer framework active
üõ°Ô∏è  Safety Quantification: ‚úÖ ICAO standards enforced

üìä PERFORMANCE SUMMARY:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model           ‚îÇ Tests    ‚îÇ Error Rate   ‚îÇ ICAO Comp   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ llama3.1:8b     ‚îÇ 10       ‚îÇ 0.00%        ‚îÇ 80.00%      ‚îÇ
‚îÇ mistral:7b      ‚îÇ 10       ‚îÇ 0.00%        ‚îÇ 70.00%      ‚îÇ
‚îÇ codellama:7b    ‚îÇ 10       ‚îÇ 0.00%        ‚îÇ 60.00%      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üéâ Testing completed successfully!
üìÅ Results saved to: test_results/comprehensive_test_20250729_121531.log
üìà Visualizations: test_results/*.png
```

## üîÑ Continuous Integration

### Automated Testing Pipeline
```bash
# Run full validation pipeline
bash scripts/sanity_run.sh              # Linux/macOS
PowerShell scripts/sanity_run.ps1       # Windows

# Expected pipeline stages:
# 1. System validation
# 2. Quick test run  
# 3. Memory system check
# 4. Agent functionality test
# 5. Full comprehensive test
```

### Results Analysis
```bash
# Analyze test results programmatically
python -m testing.result_analyzer test_results/

# Generate summary reports
python testing/result_streamer.py --input test_results/ --output summary.json
```

## üéØ Citation

If you use this framework in your research, please cite:

```bibtex
@software{llm_atc_hal_2025,
  title={LLM-ATC-HAL: Embodied LLM Air Traffic Controller with Safety Metrics},
  author={LLM-ATC-HAL Research Team},
  year={2025},
  url={https://github.com/Somnathab3/LLM-ATC-HAL},
  version={0.1.0},
  note={Comprehensive hallucination testing framework for safety-critical AI systems}
}
```

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`python comprehensive_hallucination_tester_v2.py`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open Pull Request

### Contribution Guidelines
- All new features must include tests
- Maintain backward compatibility where possible
- Follow existing code style and patterns
- Add documentation for new modules/functions
- Ensure system validation passes

## üìû Support

- üìñ [Documentation](CLEANUP_SUMMARY.md)
- üêõ [Issue Tracker](https://github.com/Somnathab3/LLM-ATC-HAL/issues)
- üí¨ [Discussions](https://github.com/Somnathab3/LLM-ATC-HAL/discussions)

### Getting Help
1. Check existing issues and discussions
2. Run system validation: `python deficiency_check_fixed.py`
3. Review logs in `logs/` directory
4. Provide system configuration details when reporting issues

---

**Research Contact**: For academic collaboration and research inquiries, please open a discussion or issue.

**System Status**: ‚úÖ Operational (Last validated: 2025-07-29)
**Testing Framework**: üß™ Comprehensive (39/39 tests passing)
**Safety Compliance**: üõ°Ô∏è ICAO Standards (76.92% compliance rate)
